{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS145 Howework 2\n",
    "\n",
    "\n",
    "<span style=\"color:red\"> **Important Note:** </span>\n",
    "HW2 is due on **11:59 PM PT, May 1 (Monday)**. Please submit the exported pdf file on GradeScope.\n",
    "\n",
    "## Print Out Your Name and UID\n",
    "\n",
    "<span style=\"color:blue\"> **Name: Warren Pagsuguiron, UID: 205314301** </span>\n",
    "\n",
    "## Before You Start\n",
    "\n",
    "You need to first create HW2 conda environment specified in the `cs145hw2.yml` file. If you have `conda` properly installed, you may create, activate or deactivate using:\n",
    "\n",
    "```\n",
    "conda env create -f cs145hw2.yml\n",
    "conda activate hw2\n",
    "conda deactivate\n",
    "```\n",
    "OR \n",
    "\n",
    "```\n",
    "conda env create --name NAMEOFYOURCHOICE -f cs145hw2.yml \n",
    "conda activate NAMEOFYOURCHOICE\n",
    "conda deactivate\n",
    "```\n",
    "To view the list of all your environments, use the following command:\n",
    "```\n",
    "conda env list\n",
    "```\n",
    "\n",
    "[Conda Docs](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html)\n",
    "\n",
    "You must not delete any code cells in this notebook. If you change any code outside the blocks that you are allowed to edit (between `STRART/END YOUR CODE HERE`), you need to highlight these changes. You may add some additional cells to help explain your results and observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can successfully run the code above, there will be no problem for environment setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Attribute Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classifiers, misclassification rate is commonly used to measure the final performance. However, when selecting which attribute to split in a decision tree, we often use other measures, such as information gain, gain ratio, and Gini index. Let's investigate these different measures through the following problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: To compute the misclassification rate of a classification tree with N data points, K classes, and M leaf nodes:\n",
    "\n",
    "In a node m, m = 1, ..., M, let $N_m$ denote the number of data points, and $N_{mk}$ denote the number of data points in class k.\n",
    "The prediction under majority vote can thus be written as $j = argmax_k N_{mk}$.\n",
    "The misclassification rate of this node is $R_m = 1 - \\frac{N_{mj}}{N_m}$.\n",
    "The misclassification rate of the entire tree would be $R = \\frac{\\sum_{m=1}^M R_m * N_m}{N}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Questions**\n",
    "\n",
    "<span style=\"color:red\"> Note: this question does not require any coding. </span>\n",
    "\n",
    "Suppose our dataset includes a total of 800 people with 400 males and 400 females, and our goal is to perform gender classification.\n",
    "Consider two potential attributes we can split on in a decision tree. Splitting on the first attribute results in a node11 with 300 male and 100 female, and a node12 with 100 men and 300 women. Splitting on the second attribute results in a node21 with 400 men and 200 women, and a node22 with no men and 200 women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Which attribute would you prefer if we optimize for misclassifcation rate, and why?\n",
    "2. What is the entropy of each of these four node? \n",
    "3. What is the information gain of each of the two splits?\n",
    "4. Which attribute do you prefer if we optimize for measurement is information gain?\n",
    "5. What is the gain ratio (normalized information gain) of each of the two splits? Which attribute would you prefer if we optimize for gain ratio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The attribute doesn't matter because the missclassification rate for both attributes would be the same.\n",
    "\n",
    "node 1\n",
    "\n",
    "$ R = \\frac{(400-300)+(400-300)}{800} = 0.25 $\n",
    "\n",
    "node 2\n",
    "\n",
    "$ R = \\frac{(600-400)+(200-200)}{800} = 0.25  $\n",
    "\n",
    "2.   \n",
    "\n",
    "$ H_{11}(Y) = H_{12}(Y) = -\\frac{300}{400}\\log{\\frac{300}{400}}-\\frac{100}{400}\\log{\\frac{100}{400}} = 0.8113 $\n",
    "\n",
    "$ H_{21}(Y) = -\\frac{400}{600}\\log{\\frac{400}{600}}-\\frac{200}{600}\\log{\\frac{200}{600}} = 0.9183 $\n",
    "\n",
    "$ H_{22}(Y) = 0-\\frac{200}{200}\\log{\\frac{200}{200}} = 0 $\n",
    "\n",
    "3. \n",
    "\n",
    "attribute 1\n",
    "\n",
    "$ 1 - (\\frac{400}{800}*0.8113+\\frac{400}{800}*0.8113) = 0.1887 $\n",
    "\n",
    "attribute 2\n",
    "\n",
    "$ 1 - (\\frac{600}{800}*0.9183+\\frac{200}{800}*0) = 0.3113 $\n",
    "\n",
    "4. I would choose the second attribute\n",
    "\n",
    "\n",
    "5. \n",
    "\n",
    "Attribute 1\n",
    "\n",
    "$ SplitInfo = H_{11} + H_{12} == 1.6226 $\n",
    "\n",
    "$ --> GainRatio = 0.1887 / 1.6226 = 0.1163 $\n",
    "\n",
    "Attribute 2\n",
    "\n",
    "$ SplitInfo = H_{21} + H_{22} == 0.9183 $\n",
    "\n",
    "$ --> GainRatio = 0.3113 / 0.9183 = 0.3390 $\n",
    "\n",
    "therefore, choose attribute 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to build a decision tree model to predict the the animal `type`. We will use the `zoo` dataset, which has been preprocessed and splited into `decision-tree-train.csv` and `decision-tree-test.csv` for you.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (80, 17)\n",
      "Testing data shape: (21, 17)\n"
     ]
    }
   ],
   "source": [
    "from hw2code.decision_tree import DecisionTree\n",
    "mytree = DecisionTree()\n",
    "mytree.load_data('./data/decision-tree-train.csv','./data/decision-tree-test.csv')\n",
    "# The size of the training data: (80, 17) and testing data: (21, 17)\n",
    "print('Training data shape: ', mytree.train_data.shape)\n",
    "print('Testing data shape:', mytree.test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Infomation gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the `make_tree` and `compute_info_gain` function in `decision_tree.py`. \n",
    "\n",
    "Train you model using `info_gain` measure to classify `type` and print the test accuracy.\n",
    "\n",
    "Hint: the test accuracy should be above 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_feature is:  legs\n",
      "best_feature is:  fins\n",
      "best_feature is:  toothed\n",
      "best_feature is:  eggs\n",
      "best_feature is:  hair\n",
      "best_feature is:  hair\n",
      "best_feature is:  toothed\n",
      "best_feature is:  aquatic\n",
      "Test accuracy is:  0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "mytree = DecisionTree()\n",
    "mytree.load_data('./data/decision-tree-train.csv','./data/decision-tree-test.csv')\n",
    "test_acc= 0\n",
    "#========================#\n",
    "# START YOUR CODE HERE  #\n",
    "#========================#\n",
    "y_name = 'type'\n",
    "mytree.train(y_name, 'info_gain')\n",
    "test_acc = mytree.test(y_name)\n",
    "\n",
    "#========================#\n",
    "#   END YOUR CODE HERE   #\n",
    "#========================# \n",
    "print('Test accuracy is: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Gain ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the `compute_gain_ratio` function in `decision_tree.py`. \n",
    "\n",
    "Train you model using `gain_ratio` measure to classify `type` and print the test accuracy.\n",
    "\n",
    "Hint: the test accuracy should be above 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_feature is:  milk\n",
      "best_feature is:  feathers\n",
      "best_feature is:  toothed\n",
      "best_feature is:  breathes\n",
      "best_feature is:  eggs\n",
      "best_feature is:  fins\n",
      "best_feature is:  legs\n",
      "Test accuracy is:  0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "mytree = DecisionTree()\n",
    "mytree.load_data('./data/decision-tree-train.csv','./data/decision-tree-test.csv')\n",
    "test_acc = 0\n",
    "#========================#\n",
    "# START YOUR CODE HERE  #\n",
    "#========================#\n",
    "y_name = 'type'\n",
    "mytree.train(y_name, 'gain_ratio')\n",
    "test_acc = mytree.test(y_name)\n",
    "#========================#\n",
    "#   END YOUR CODE HERE   #\n",
    "#========================# \n",
    "print('Test accuracy is: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Homework 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
